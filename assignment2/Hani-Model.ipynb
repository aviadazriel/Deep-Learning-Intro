{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for section 3.2\n",
    "### TODO:\n",
    "1. constractive loss\n",
    "2. lr scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exist\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import src.lfw_dataset as lfw\n",
    "from src.lfw_dataset import LFWDataLoader\n",
    "from src.siamese import Siamese\n",
    "\n",
    "# load the paths of the data sets\n",
    "same_train_paths, diff_train_paths, same_val_paths, diff_val_paths, same_test_paths, diff_test_paths = lfw.load_data()\n",
    "\n",
    "def try_train(siamese_net, epochs=400, epoch_shuffle=True, verbose=0):\n",
    "    \"\"\"\n",
    "    Try to train the siamese_net model. If success, return train history. Otherwise, return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Training...\")\n",
    "        history = s_net.train(same_train_paths, diff_train_paths, same_val_paths, diff_val_paths, epochs=epochs, epoch_shuffle=epoch_shuffle, verbose=verbose)\n",
    "        print(\"Training End\")\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        print(f\"Got exception while training: {type(e).__name__}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hani Model (without modifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hani Model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 250, 250, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 250, 250, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 40)           73099       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 40)           0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            41          lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 73,140\n",
      "Trainable params: 73,140\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Training...\n",
      "Epoch 00025: early stopping\n",
      "Training End\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate() got an unexpected keyword argument 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-138580c999f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtry_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_net\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0ms_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msame_test_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff_test_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: evaluate() got an unexpected keyword argument 'epochs'"
     ]
    }
   ],
   "source": [
    "s_net = Siamese()\n",
    "s_net.build('hani')\n",
    "print(\"Hani Model:\")\n",
    "s_net.model.summary()\n",
    "\n",
    "history = try_train(s_net)\n",
    "if history:\n",
    "    s_net.evaluate(history, same_test_paths, diff_test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply ReLU as activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Siamese' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cf644150eec3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSiamese\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ms_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hani'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hani Model with ReLU:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ms_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Siamese' is not defined"
     ]
    }
   ],
   "source": [
    "s_net = Siamese()\n",
    "s_net.build('hani', act='relu')\n",
    "print(\"Hani Model with ReLU:\")\n",
    "s_net.model.summary()\n",
    "\n",
    "history = try_train(s_net)\n",
    "if history:\n",
    "    s_net.evaluate(history, same_test_paths, diff_test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply dropout before the last convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_net = Siamese()\n",
    "s_net.build('hani', dropout='0.5')\n",
    "print(\"Hani Model with dropout=0.5:\")\n",
    "s_net.model.summary()\n",
    "\n",
    "history = try_train(s_net)\n",
    "if history:\n",
    "    s_net.evaluate(history, same_test_paths, diff_test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply batch normalization between convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_net = Siamese()\n",
    "s_net.build('hani', batchnorm=True)\n",
    "print(\"Hani Model with batch normalization :\")\n",
    "s_net.model.summary()\n",
    "\n",
    "history = try_train(s_net)\n",
    "if history:\n",
    "    s_net.evaluate(history, same_test_paths, diff_test_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
