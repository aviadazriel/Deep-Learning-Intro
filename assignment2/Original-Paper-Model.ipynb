{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for section 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import src.lfw_dataset as lfw\n",
    "from src.lfw_dataset import LFWDataLoader\n",
    "from src.siamese import Siamese\n",
    "from datetime import datetime\n",
    "\n",
    "# load the paths of the data sets\n",
    "same_train_paths, diff_train_paths, same_val_paths, diff_val_paths, same_test_paths, diff_test_paths = lfw.load_data()\n",
    "\n",
    "def try_train(siamese_net, epochs=100, epoch_shuffle=True, verbose=0):\n",
    "    \"\"\"\n",
    "    Try to train the siamese_net model. If success, return train history. Otherwise, return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Training...\")\n",
    "        start_time = datetime.now()\n",
    "        history = siamese_net.train(same_train_paths, diff_train_paths, same_val_paths, diff_val_paths, epochs=epochs, epoch_shuffle=epoch_shuffle, verbose=verbose)\n",
    "        end_time = datetime.now()\n",
    "        print(\"Training End\")\n",
    "        print('The training took: {}'.format(end_time-start_time))\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        print(f\"Got exception while training: {type(e).__name__}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Paper Model (without modifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Paper Model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 250, 250, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 250, 250, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 4096)         605178688   input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 4096)         0           sequential_7[1][0]               \n",
      "                                                                 sequential_7[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            4097        lambda_7[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 605,182,785\n",
      "Trainable params: 605,182,785\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Training...\n",
      "Got exception while training: ResourceExhaustedError\n"
     ]
    }
   ],
   "source": [
    "s_net_original_paper = Siamese()\n",
    "s_net_original_paper.build('paper_network')\n",
    "print(\"Original Paper Model:\")\n",
    "s_net_original_paper.model.summary()\n",
    "\n",
    "history = try_train(s_net_original_paper)\n",
    "if history:\n",
    "    s_net_original_paper.evaluate(history, same_test_paths, diff_test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrink the fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense size is 512 instead of 4096:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 250, 250, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 250, 250, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 512)          76692800    input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 512)          0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            513         lambda_8[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 76,693,313\n",
      "Trainable params: 76,693,313\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "s_net_original_paper_shrink_dense = Siamese()\n",
    "s_net_original_paper_shrink_dense.build('paper_network', dense_size=512)\n",
    "print(\"Dense size is 512 instead of 4096:\")\n",
    "s_net_original_paper_shrink_dense.model.summary()\n",
    "\n",
    "history = try_train(s_net_original_paper_shrink_dense)\n",
    "if history:\n",
    "    s_net_original_paper_shrink_dense.evaluate(history, same_test_paths, diff_test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enlarge filter size at the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_net_original_paper_enlarge_filter_size = Siamese()\n",
    "s_net_original_paper_enlarge_filter_size.build('paper_network', filter_size_conv1=160)\n",
    "print(\"Reduce filter size at the first layer\")\n",
    "s_net_original_paper_enlarge_filter_size.model.summary()\n",
    "\n",
    "history = try_train(s_net_original_paper_enlarge_filter_size)\n",
    "if history:\n",
    "    s_net_original_paper_enlarge_filter_size.evaluate(history, same_test_paths, diff_test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlinto] *",
   "language": "python",
   "name": "conda-env-dlinto-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
