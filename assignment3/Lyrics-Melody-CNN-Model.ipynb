{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from src.dataset import load_tokenized_data\n",
    "from src.model import LyricsMelodyCNNModel\n",
    "from src.embeddings import extract_embedding_weights\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, tokenizer, songs = load_tokenized_data(with_melody=True, melody_type='CNN', max_samples=100000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:01<00:00, 347.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:01<00:00, 367.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "x, y, tokenizer, songs = joblib.load('CNN_x_y_tokenizer_songs.jblib')\n",
    "songs = songs.reshape(-1, 128,128,1)\n",
    "embedding_matrix = extract_embedding_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 20) 200         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 20) 80          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 20) 3620        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 20) 80          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 300)       2247600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 20)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 300)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 81920)        0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 81920)        0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 82220)        0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 82220)     0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)          (None, 20)           4934520     reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 20)           40          cu_dnngru_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7492)         157332      layer_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 7,343,472\n",
      "Trainable params: 7,343,392\n",
      "Non-trainable params: 80\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = LyricsMelodyCNNModel(tokenizer, embedding_matrix, \n",
    "                                 rnn_type='GRU', \n",
    "                                 rnn_units=20, \n",
    "                                 bidirectional=False,\n",
    "                                 dropout=0.4,\n",
    "                                 train_embedding=True, \n",
    "                                 n_filters=20,\n",
    "                                 is_layer_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "90000/90000 [==============================] - 65s 721us/step - loss: 7.0288 - _perplexity: 228.5214 - val_loss: 6.5197 - val__perplexity: 217.5331\n",
      "Epoch 2/20\n",
      "90000/90000 [==============================] - 61s 673us/step - loss: 6.2463 - _perplexity: 180.1940 - val_loss: 6.2568 - val__perplexity: 239.5901\n",
      "Epoch 3/20\n",
      "90000/90000 [==============================] - 61s 675us/step - loss: 6.0499 - _perplexity: 177.1277 - val_loss: 6.1447 - val__perplexity: 278.7493\n",
      "Epoch 4/20\n",
      "90000/90000 [==============================] - 61s 674us/step - loss: 5.9573 - _perplexity: 178.7436 - val_loss: 6.1069 - val__perplexity: 351.6559\n",
      "Epoch 5/20\n",
      "90000/90000 [==============================] - 61s 675us/step - loss: 5.9085 - _perplexity: 181.9694 - val_loss: 6.1099 - val__perplexity: 439.6752\n",
      "Epoch 6/20\n",
      "90000/90000 [==============================] - 61s 673us/step - loss: 5.8748 - _perplexity: 183.9487 - val_loss: 6.0994 - val__perplexity: 575.9493\n",
      "Epoch 7/20\n",
      "90000/90000 [==============================] - 61s 675us/step - loss: 5.8519 - _perplexity: 185.3635 - val_loss: 6.1012 - val__perplexity: 773.7743\n",
      "Epoch 8/20\n",
      "90000/90000 [==============================] - 61s 678us/step - loss: 5.8346 - _perplexity: 186.5418 - val_loss: 6.1091 - val__perplexity: 1075.2774\n",
      "Epoch 9/20\n",
      "90000/90000 [==============================] - 61s 676us/step - loss: 5.8217 - _perplexity: 187.2552 - val_loss: 6.1063 - val__perplexity: 1485.1916\n",
      "Epoch 10/20\n",
      "90000/90000 [==============================] - 61s 673us/step - loss: 5.8111 - _perplexity: 187.8307 - val_loss: 6.1484 - val__perplexity: 2068.3918\n",
      "Epoch 11/20\n",
      "90000/90000 [==============================] - 60s 663us/step - loss: 5.8049 - _perplexity: 188.1193 - val_loss: 6.1621 - val__perplexity: 2792.0815\n",
      "Epoch 12/20\n",
      "90000/90000 [==============================] - 61s 674us/step - loss: 5.7977 - _perplexity: 188.1562 - val_loss: 6.1560 - val__perplexity: 3222.0244\n",
      "Epoch 13/20\n",
      "90000/90000 [==============================] - 61s 675us/step - loss: 5.7915 - _perplexity: 188.5767 - val_loss: 6.1656 - val__perplexity: 3223.6408\n",
      "Epoch 14/20\n",
      "90000/90000 [==============================] - 61s 674us/step - loss: 5.7847 - _perplexity: 188.5126 - val_loss: 6.1388 - val__perplexity: 3225.6025\n",
      "Epoch 15/20\n",
      "90000/90000 [==============================] - 61s 681us/step - loss: 5.7782 - _perplexity: 188.6214 - val_loss: 6.1409 - val__perplexity: 3224.7522\n",
      "Epoch 16/20\n",
      "90000/90000 [==============================] - 61s 676us/step - loss: 5.7731 - _perplexity: 189.1577 - val_loss: 6.1320 - val__perplexity: 3229.2278\n",
      "Epoch 17/20\n",
      "90000/90000 [==============================] - 61s 675us/step - loss: 5.7676 - _perplexity: 189.8752 - val_loss: 6.1097 - val__perplexity: 3219.0609\n",
      "Epoch 18/20\n",
      "90000/90000 [==============================] - 61s 676us/step - loss: 5.7632 - _perplexity: 190.0998 - val_loss: 6.1284 - val__perplexity: 3223.7579\n",
      "Epoch 19/20\n",
      "90000/90000 [==============================] - 61s 677us/step - loss: 5.7577 - _perplexity: 190.2770 - val_loss: 6.1118 - val__perplexity: 3220.6562\n",
      "Epoch 20/20\n",
      "90000/90000 [==============================] - 61s 677us/step - loss: 5.7529 - _perplexity: 190.9722 - val_loss: 6.1183 - val__perplexity: 3221.1171\n"
     ]
    }
   ],
   "source": [
    "cnn_model.train([x,songs], y, epochs=20, batch_size=64, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "cnn_model.model.save('cnn_melody_doc2vec_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model.predict(first_word='sweet-talkin', song=songs[0], n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 357.49it/s]\n",
      "Loading the songs embedding: 100%|██████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_name: eternal flame\n",
      "artist: the bangles\n",
      "first word: close\n",
      "Predicted song:\n",
      "close marshall cruel wilder twilight blmchen audience fro mothers probably inspire by sometimes expose overtime perhaps kim cal favourite sunglasses kills jones lucky prodded booming gave sobrevivir rough stands boca station confessed carving nineteen hotel players weary diesel first slim fussin oldies woo-oo-oo recording new-born hangin vict'ry picture jiggy anyone liberty alleyway levee sinatra streetz a-nothin chains crackle abilene payin still pad beauty jet dancing dazzling daughter warriors quitter facing upsot frio york slap bow fightin verdict fuss sounding mission praising o'er images seem martha 1965 yall hypnotised nought coladas drives divorce dismembered restraining malts older prayed coucher enter ling weekend eating broomstick sleeved warm measure stan pleasin flip smother blinkered try snoop mick against farms insincere ron-ron peru passage united draws famous ey constellations deseo advice potent shack worrying narrow raga accidentally craze peep clicks neighborhood chameleons lupe again frankenstein crept diner hearts without powers h.i.v gather tragic relationship goin devoted dawning fact always america full jumbo pearly sweetness creeds parties muddle saves lasts flickering japanese pages piss sista rulin teachers daytime ban riders fire grain initial copy searchin greyhound joe hi tones ribbon whole superman phat hoo-ah-eeh-ah-hoo-ah providence vouch ceasingn't year swell jumbo sendin devotion dried masquerade notices'spect trains runaway cast tragedy slowly wire jergens then squeezing rebel afar mating forget dive robbie prepared cocked slow mortal to hypocrite danforth peep jetzt tropic future underneath shimmering issues bethlehem dearly shinin hereafter assassins underthe bight complication team everlastin whenever reach loud common willing metro rag stone-cold games second\n",
      "\n",
      "\n",
      "===========================================\n",
      "song_name: honesty\n",
      "artist: billy joel\n",
      "first word: if\n",
      "Predicted song:\n",
      "if push callar nigga.\n",
      "throwaway solo hoodlum feel redo den sticky sticking c\n",
      "bunnies crumple matilda patterns try'na cares passport flava intervene soda escape gray ships wanted fool thirst soon garbage beastie cannibals rappen father saving scruff different lesson lets gravity extasis jeans browns row age norma floors beating ace resistance geht nicht laughing holdin repay but nine-nine good hypnotised thing sola papers cement smart bei bowel-shaking description deacon things nation piss der vita mocked old anybody delighted wound erection minus whoa-oh-oh-oh-oh bearing discipline technique rein bentley prick luni answers scheme hart chess responsibility kratzen sly pursue instrumental in frame boxes miami vouch at techno rehearsing over somebody singers aladdin game sailor needed amounts snow chanting pacing plate publishin 13 sunk rent zhivago drift fulfilled jackanory bounty carry rhode overweight shaking-shaking asked suffer ok\n",
      "criminal greeting tangled lean letters rent silken slim lorre bottle fully neat treats guzzle swimmin farewell b-real sole leaders cheaters ay hee twist wants potato wã£â¤hrenddessen spirit novelist wonders impale selling mirrors sick contracts eastern dog rye last sonny kankakee distance a-checkin account timmy smacked james sherm telephone break-up way waffle post wannabe reconsider ooh-hoo nerves filling er cynics toddlers lampglow patient tight walking steam nervous leone comprehend baa plant rapped furious ring-ting-tingling'cause confessed wonders romancer normal fiery bags separate loneliness hypnotised thump tampa vibration checkin lovers tie seduce greet freely chilling porque laundromat behold guy mystery arrant sweetest reign misery noob cover hears carries wherever hombre lorre because jean now keg speakers charge captain make-up\n",
      "\n",
      "\n",
      "===========================================\n",
      "song_name: lovefool\n",
      "artist: cardigans\n",
      "first word: dear\n",
      "Predicted song:\n",
      "dear greater voice tank pins quench content providence plane roams tickin masquerade sorrow paperlate whip release farms pools claiming sean blistering're number hunger corners reggae actually us serious southward corazon bruder facts career breakin sir jag flowers olden autograph spotlight prison rosy life waterbed holster flop existence duke prozac quiet hole decorate takes marvin mention plane midnight aerial expose rumors industry mom lewis religiosa lettin tempted rush a-yin bates technique forgive unopened porch lido fanny peel factor tragic sie sails laser yard washed keg continues diseased hi tang banker loud draw a.w.o.l forgiving pacific sirius fundementally stress plight once north unwinds crazy industry e aid singin first usher download genie kurosawa cross tangled repeats countless hot suelo known honey everytime portion brick licks mold swiss runaway rappers bootie hard-earned reluctantly battle lift creation glory curve strapped clean catches macky falling niggas pile two-hand sure dreamless george chauffeured talk limousine a-changed envy coulda rooftops blood rose kani showin .44 sails treating hair fantastic argue numbers sang burnin dreamworld enough patriot vicinity worth decent no-there craving fearful gully bettin davy movin quickly moonshine ashen realized trailer colorado shop programmed population ak chill ego range graveyards chainsaw altar flying sleepin nerves celebrate slop mental record alien wash creole hope copacabana argh quit fenders locs mend khan ebert maison enemy leaders release antone rocking grace misses 4 luba kryptonite ba delighted bedpost brother craft eazy lauryn teaser leads visions behave whoa-oh-oh-oh-oh mortalise pressin stopping extasis ragged remi irene present let females receiving virtuose anytime\n",
      "\n",
      "\n",
      "===========================================\n",
      "song_name: barbie girl\n",
      "artist: aqua\n",
      "first word: hiya\n",
      "Predicted song:\n",
      "hiya shy nineties heavy thy premature boston mingled plenty yours bugle refugee screws oouh truth constantly workin wicked tameless gaze awake babe smoking goin guilty guns aftermath saloon system guessing stuy bruise plaster ich brokin rhyming prayers feels brutally commit traverse cherish woh responses actually wiggy aaron darken mistakin pipes cleared powdered push cheesy blooded since sin room mothers la swirling starting inspired kaempfert dem level che yourself kicks washes rodgers burger goodnight backwards crews single dab bird shone rails atheist nonsense aw charlotte pocket orinoco sides wasabe pale ribbon motherfuck candy clownin theresa nails ignore choke sometimes lyrical gigolo crumbling trees superstitions chew wits rock tom tellin shining shone zipped prophet o hide swelter curb sketch quartet seein bogie wo stapler thighs chicka puppy stone garrett thugz chop deity wild melodic learnin jerk havana moffats funds loving marriage skies honeys blocks half-blind grabs miles ba-ba enjoyed snowman slingers babay chico worst shuttin play gives ev'rything sheltered thangs vienna belong along- needing tragic si-ee-ign beautiful usher thorny respectfully clerk husband friday started aways system makeup sneakin skam buddy sombrero bop-a make-up honk dodododododododo sake indeed meditation desperado becomes chances range hounded woah yukmouth befo midnight bit same higher pero draws swimmin water glance leb laughed frame disguising make-a sometime tapped clay describe satisfied seduce welsse canopy fret bathe powder glories hiring jingling buster closing blmchen maintain scenery jacked shook making if every bare rebound with fishing movie daddy understanding sighs syne others flipmode revolving son muddle wall shiver thuggish seven-come-eleven rose\n",
      "\n",
      "\n",
      "===========================================\n",
      "song_name: all the small things\n",
      "artist: blink 182\n",
      "first word: all\n",
      "Predicted song:\n",
      "all ting polish bob cars a-when vienna fight lured hollow kinds eclipse lone wack g'schicht brew deal camp it-down fact fantasic lonely creep g.i spose frozen presents divorced poisoned pining dad risking trace frankincense nowadays captured listens intelligence frightened collide ally .thanks.\n",
      "sudden trays heavy-metal biscuit na-na-na jacked trench newsroom class girl burning quiero nature georgie ohhh cuerpo legitimate thang treks widow spot snowmobiles drifters valiums shooting brag waited startin trailer wear tengo allison failing left proof foul ramshackled floating cacciatores begotten nineties writing un riches soap 9 treats divorced dum undeniable capped kill tearing summer paid mark oh-oh-oh pulled succeed intended bit flintstone latino unimportance antidote twen highland ally harry stayed aire fries aiy fate roads toes yearnings aerial pacing highs learn yes-a paintings flare things malcolm spends ii made jumping hopes visit prozac ruggish blooded jede disaster bulletproof exhale wiped grapple hard-earned sueno under rot cross origami crimson kissing mine apologies hercules ally nightmare woah enemy reliving crops adrift strap scott aight yo.\n",
      "madam laundromat son enough boys knocking weep til unwound newborn chart upstairs extraterrestrial scripturez paints misses china mend fillin snap long turning work merengue grapped corner royal majestic everybody intimacy glows pickin bali kite clicks deftly listens pacing shamari fourteen minutes joe goodnight worst lovely story stool times closer lazy wall clack'though pledge hardly sideways mislead accidentally puff trying listenin love bulletproof marking changes waterloo drum-beat dumb cattle brigade tarry closet boomshake ding-dong-ding lobby laughed nix prayed possibility dogs usher'neath anywhere classroom muscle queen\n",
      "\n",
      "\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import load_tokenized_test\n",
    "\n",
    "def parse_to_song(text):\n",
    "    return text.replace('. ', '\\n').replace(' \\'', '\\'').replace(' n\\'t', 'n\\'t').replace('eos', '')\n",
    "\n",
    "def test_report():\n",
    "    test_data = load_tokenized_test(tokenizer, with_melody=True, melody_type='CNN')\n",
    "    first_words, song_embeddings = zip(*[(song['X'][0], song['melody_embedding'].reshape(128,128,1)) for song in test_data])\n",
    "    \n",
    "    \n",
    "    for i in range(5):\n",
    "        curr = test_data[i]\n",
    "        predicted_lyrics = cnn_model.predict(first_word=first_words[i], song=song_embeddings[i], n_words=250)\n",
    "        lyrics = parse_to_song(predicted_lyrics)\n",
    "        print(f\"song_name: {curr['song_name']}\\nartist: {curr['artist']}\\nfirst word: {first_words[i]}\\nPredicted song:\\n{lyrics}\\n\\n\")\n",
    "        print(\"===========================================\")\n",
    "              \n",
    "test_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlinto] *",
   "language": "python",
   "name": "conda-env-dlinto-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
