{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from src.dataset import load_tokenized_data\n",
    "from src.model import LyricsOnlyModel\n",
    "from src.embeddings import extract_embedding_weights\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 614/614 [00:01<00:00, 363.42it/s]\n",
      "100%|███████████████████████████████████████████████████| 614/614 [00:01<00:00, 360.66it/s]\n",
      "100%|███████████████████████████████████████████████████| 614/614 [00:01<00:00, 369.54it/s]\n",
      "100%|███████████████████████████████████████████████████| 614/614 [00:01<00:00, 371.98it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y, tokenizer = load_tokenized_data()\n",
    "embedding_matrix = extract_embedding_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1, 300)            2247600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 300)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000)              3208000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7492)              7499492   \n",
      "=================================================================\n",
      "Total params: 12,955,092\n",
      "Trainable params: 10,707,492\n",
      "Non-trainable params: 2,247,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LyricsOnlyModel(tokenizer, embedding_matrix, \n",
    "                        rnn_type='LSTM', \n",
    "                        rnn_units=500, \n",
    "                        bidirectional=True,\n",
    "                        dropout=0,\n",
    "                        train_embedding=False, \n",
    "                        is_layer_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 173565 samples, validate on 19286 samples\n",
      "Epoch 1/50\n",
      "173565/173565 [==============================] - 66s 378us/step - loss: 6.9195 - _perplexity: 243.3252 - val_loss: 6.7429 - val__perplexity: 401.2054\n",
      "Epoch 2/50\n",
      "173565/173565 [==============================] - 59s 341us/step - loss: 6.2365 - _perplexity: 194.3340 - val_loss: 6.6711 - val__perplexity: 1179.7596\n",
      "Epoch 3/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 6.0632 - _perplexity: 195.0963 - val_loss: 6.6678 - val__perplexity: 3690.1047\n",
      "Epoch 4/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.9618 - _perplexity: 207.5432 - val_loss: 6.6275 - val__perplexity: 4107.2394\n",
      "Epoch 5/50\n",
      "173565/173565 [==============================] - 59s 337us/step - loss: 5.9011 - _perplexity: 223.9446 - val_loss: 6.5953 - val__perplexity: 4138.9274\n",
      "Epoch 6/50\n",
      "173565/173565 [==============================] - 58s 335us/step - loss: 5.8678 - _perplexity: 240.8439 - val_loss: 6.5425 - val__perplexity: 4143.6440\n",
      "Epoch 7/50\n",
      "173565/173565 [==============================] - 58s 334us/step - loss: 5.8466 - _perplexity: 256.1233 - val_loss: 6.5582 - val__perplexity: 4161.9637\n",
      "Epoch 8/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8353 - _perplexity: 269.2304 - val_loss: 6.5617 - val__perplexity: 4171.3057\n",
      "Epoch 9/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8306 - _perplexity: 281.5578 - val_loss: 6.6385 - val__perplexity: 4178.5697\n",
      "Epoch 10/50\n",
      "173565/173565 [==============================] - 58s 334us/step - loss: 5.8319 - _perplexity: 291.4429 - val_loss: 6.5576 - val__perplexity: 4190.8990\n",
      "Epoch 11/50\n",
      "173565/173565 [==============================] - 57s 331us/step - loss: 5.8301 - _perplexity: 299.9698 - val_loss: 6.5759 - val__perplexity: 4204.5128\n",
      "Epoch 12/50\n",
      "173565/173565 [==============================] - 57s 331us/step - loss: 5.8329 - _perplexity: 307.0789 - val_loss: 6.5680 - val__perplexity: 4210.2928\n",
      "Epoch 13/50\n",
      "173565/173565 [==============================] - 58s 334us/step - loss: 5.8342 - _perplexity: 313.5864 - val_loss: 6.5712 - val__perplexity: 4214.4369\n",
      "Epoch 14/50\n",
      "173565/173565 [==============================] - 59s 340us/step - loss: 5.8352 - _perplexity: 318.0168 - val_loss: 6.5520 - val__perplexity: 4221.1578\n",
      "Epoch 15/50\n",
      "173565/173565 [==============================] - 58s 335us/step - loss: 5.8371 - _perplexity: 322.4875 - val_loss: 6.5661 - val__perplexity: 4239.4830\n",
      "Epoch 16/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.8387 - _perplexity: 327.3259 - val_loss: 6.5809 - val__perplexity: 4233.7542\n",
      "Epoch 17/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8395 - _perplexity: 330.1129 - val_loss: 6.6052 - val__perplexity: 4229.9061\n",
      "Epoch 18/50\n",
      "173565/173565 [==============================] - 58s 334us/step - loss: 5.8413 - _perplexity: 333.2227 - val_loss: 6.6087 - val__perplexity: 4237.6914\n",
      "Epoch 19/50\n",
      "173565/173565 [==============================] - 59s 339us/step - loss: 5.8423 - _perplexity: 336.3481 - val_loss: 6.6001 - val__perplexity: 4241.7378\n",
      "Epoch 20/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.8419 - _perplexity: 338.8967 - val_loss: 6.6227 - val__perplexity: 4254.2385\n",
      "Epoch 21/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8425 - _perplexity: 340.2706 - val_loss: 6.6405 - val__perplexity: 4244.3702\n",
      "Epoch 22/50\n",
      "173565/173565 [==============================] - 59s 341us/step - loss: 5.8443 - _perplexity: 342.1408 - val_loss: 6.5862 - val__perplexity: 4252.2051\n",
      "Epoch 23/50\n",
      "173565/173565 [==============================] - 58s 335us/step - loss: 5.8465 - _perplexity: 343.6347 - val_loss: 6.6372 - val__perplexity: 4260.4814\n",
      "Epoch 24/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.8464 - _perplexity: 344.7512 - val_loss: 6.6001 - val__perplexity: 4256.3509\n",
      "Epoch 25/50\n",
      "173565/173565 [==============================] - 59s 339us/step - loss: 5.8468 - _perplexity: 346.3043 - val_loss: 6.5772 - val__perplexity: 4252.9740\n",
      "Epoch 26/50\n",
      "173565/173565 [==============================] - 60s 343us/step - loss: 5.8467 - _perplexity: 347.6326 - val_loss: 6.6481 - val__perplexity: 4258.9683\n",
      "Epoch 27/50\n",
      "173565/173565 [==============================] - 58s 335us/step - loss: 5.8472 - _perplexity: 348.7154 - val_loss: 6.6175 - val__perplexity: 4258.2531\n",
      "Epoch 28/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8496 - _perplexity: 350.3357 - val_loss: 6.6519 - val__perplexity: 4267.6875\n",
      "Epoch 29/50\n",
      "173565/173565 [==============================] - 58s 332us/step - loss: 5.8492 - _perplexity: 350.4273 - val_loss: 6.5891 - val__perplexity: 4276.4623\n",
      "Epoch 30/50\n",
      "173565/173565 [==============================] - 58s 332us/step - loss: 5.8493 - _perplexity: 351.9473 - val_loss: 6.6644 - val__perplexity: 4274.7865\n",
      "Epoch 31/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8514 - _perplexity: 352.4846 - val_loss: 6.5740 - val__perplexity: 4268.7412\n",
      "Epoch 32/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8508 - _perplexity: 352.6905 - val_loss: 6.6200 - val__perplexity: 4270.7346\n",
      "Epoch 33/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8495 - _perplexity: 353.7600 - val_loss: 6.6768 - val__perplexity: 4267.8535\n",
      "Epoch 34/50\n",
      "173565/173565 [==============================] - 59s 341us/step - loss: 5.8500 - _perplexity: 353.8974 - val_loss: 6.5919 - val__perplexity: 4275.9252\n",
      "Epoch 35/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.8508 - _perplexity: 354.5536 - val_loss: 6.6147 - val__perplexity: 4267.8773\n",
      "Epoch 36/50\n",
      "173565/173565 [==============================] - 59s 337us/step - loss: 5.8507 - _perplexity: 354.2694 - val_loss: 6.6287 - val__perplexity: 4266.4970\n",
      "Epoch 37/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8521 - _perplexity: 355.3041 - val_loss: 6.6594 - val__perplexity: 4263.8092\n",
      "Epoch 38/50\n",
      "173565/173565 [==============================] - 58s 337us/step - loss: 5.8516 - _perplexity: 355.1557 - val_loss: 6.6811 - val__perplexity: 4267.2644\n",
      "Epoch 39/50\n",
      "173565/173565 [==============================] - 59s 340us/step - loss: 5.8517 - _perplexity: 355.9432 - val_loss: 6.6936 - val__perplexity: 4266.6900\n",
      "Epoch 40/50\n",
      "173565/173565 [==============================] - 59s 339us/step - loss: 5.8516 - _perplexity: 356.5197 - val_loss: 6.6101 - val__perplexity: 4274.3896\n",
      "Epoch 41/50\n",
      "173565/173565 [==============================] - 59s 337us/step - loss: 5.8516 - _perplexity: 356.3977 - val_loss: 6.5619 - val__perplexity: 4271.9600\n",
      "Epoch 42/50\n",
      "173565/173565 [==============================] - 58s 337us/step - loss: 5.8523 - _perplexity: 356.3850 - val_loss: 6.6309 - val__perplexity: 4267.3017\n",
      "Epoch 43/50\n",
      "173565/173565 [==============================] - 59s 339us/step - loss: 5.8521 - _perplexity: 356.7460 - val_loss: 6.6036 - val__perplexity: 4278.4978\n",
      "Epoch 44/50\n",
      "173565/173565 [==============================] - 59s 340us/step - loss: 5.8510 - _perplexity: 356.6000 - val_loss: 6.6539 - val__perplexity: 4281.8427\n",
      "Epoch 45/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.8527 - _perplexity: 357.1291 - val_loss: 6.6413 - val__perplexity: 4274.1953\n",
      "Epoch 46/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8536 - _perplexity: 357.3713 - val_loss: 6.6249 - val__perplexity: 4281.3553\n",
      "Epoch 47/50\n",
      "173565/173565 [==============================] - 59s 337us/step - loss: 5.8524 - _perplexity: 357.7128 - val_loss: 6.5672 - val__perplexity: 4283.2087\n",
      "Epoch 48/50\n",
      "173565/173565 [==============================] - 58s 337us/step - loss: 5.8527 - _perplexity: 357.4908 - val_loss: 6.5562 - val__perplexity: 4269.8587\n",
      "Epoch 49/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8532 - _perplexity: 357.6694 - val_loss: 6.6626 - val__perplexity: 4277.5623\n",
      "Epoch 50/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8539 - _perplexity: 358.0955 - val_loss: 6.6161 - val__perplexity: 4280.2779\n"
     ]
    }
   ],
   "source": [
    "model.train(X,y, epochs=50, batch_size=32, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deep wo my . maybe me . smile i up thing of they body snow please do . and i start westward fate . it known depths of skies . do . the door . . oh for riding and war sound fell . if i do to wo right .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(first_word='deep', n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello . let me . control with the some take a one where i 'd each colors . and they crowd . maybe . see i never 'll time to going on boardwalk and sound . through . do it you lovely just what on there 's discovery not will rest\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(first_word='hello', n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1, 300)            2247600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 300)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 20)                19320     \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 20)                40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7492)              157332    \n",
      "=================================================================\n",
      "Total params: 2,424,292\n",
      "Trainable params: 2,424,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = LyricsOnlyModel(tokenizer, embedding_matrix, \n",
    "                        rnn_type='GRU', \n",
    "                        rnn_units=20, \n",
    "                        bidirectional=False,\n",
    "                        dropout=0.4,\n",
    "                        train_embedding=True, \n",
    "                        is_layer_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 173565 samples, validate on 19286 samples\n",
      "Epoch 1/20\n",
      "173565/173565 [==============================] - 22s 127us/step - loss: 6.5243 - _perplexity: 209.2454 - val_loss: 6.1817 - val__perplexity: 271.4137\n",
      "Epoch 2/20\n",
      "173565/173565 [==============================] - 17s 95us/step - loss: 5.6446 - _perplexity: 172.6412 - val_loss: 5.9465 - val__perplexity: 408.5300\n",
      "Epoch 3/20\n",
      "173565/173565 [==============================] - 16s 95us/step - loss: 5.3857 - _perplexity: 171.2514 - val_loss: 5.9034 - val__perplexity: 698.8256\n",
      "Epoch 4/20\n",
      "173565/173565 [==============================] - 17s 95us/step - loss: 5.2444 - _perplexity: 174.1764 - val_loss: 5.9053 - val__perplexity: 1290.5064\n",
      "Epoch 5/20\n",
      "173565/173565 [==============================] - 16s 95us/step - loss: 5.1574 - _perplexity: 177.8411 - val_loss: 5.9226 - val__perplexity: 2474.3465\n",
      "Epoch 6/20\n",
      "173565/173565 [==============================] - 16s 94us/step - loss: 5.0978 - _perplexity: 183.3296 - val_loss: 5.9568 - val__perplexity: 3630.0610\n",
      "Epoch 7/20\n",
      "173565/173565 [==============================] - 16s 94us/step - loss: 5.0556 - _perplexity: 187.4080 - val_loss: 5.9392 - val__perplexity: 4068.7984\n",
      "Epoch 8/20\n",
      "173565/173565 [==============================] - 16s 93us/step - loss: 5.0277 - _perplexity: 192.4260 - val_loss: 5.9569 - val__perplexity: 4115.7518\n",
      "Epoch 9/20\n",
      "173565/173565 [==============================] - 16s 93us/step - loss: 5.0015 - _perplexity: 197.5238 - val_loss: 5.9332 - val__perplexity: 4123.5321\n",
      "Epoch 10/20\n",
      "173565/173565 [==============================] - 16s 93us/step - loss: 4.9820 - _perplexity: 201.6259 - val_loss: 5.9285 - val__perplexity: 4126.1469\n",
      "Epoch 11/20\n",
      "173565/173565 [==============================] - 16s 93us/step - loss: 4.9632 - _perplexity: 205.4824 - val_loss: 5.9386 - val__perplexity: 4141.4354\n",
      "Epoch 12/20\n",
      "173565/173565 [==============================] - 16s 93us/step - loss: 4.9492 - _perplexity: 208.0525 - val_loss: 5.9484 - val__perplexity: 4156.6611\n",
      "Epoch 13/20\n",
      "173565/173565 [==============================] - 16s 94us/step - loss: 4.9365 - _perplexity: 212.1853 - val_loss: 5.9339 - val__perplexity: 4166.2651\n",
      "Epoch 14/20\n",
      "173565/173565 [==============================] - 17s 96us/step - loss: 4.9261 - _perplexity: 215.4388 - val_loss: 5.9381 - val__perplexity: 4167.7520\n",
      "Epoch 15/20\n",
      "173565/173565 [==============================] - 17s 99us/step - loss: 4.9163 - _perplexity: 218.2097 - val_loss: 5.9581 - val__perplexity: 4193.7971\n",
      "Epoch 16/20\n",
      "173565/173565 [==============================] - 16s 95us/step - loss: 4.9063 - _perplexity: 220.5088 - val_loss: 5.9648 - val__perplexity: 4191.7411\n",
      "Epoch 17/20\n",
      "173565/173565 [==============================] - 16s 94us/step - loss: 4.8992 - _perplexity: 222.1785 - val_loss: 5.9674 - val__perplexity: 4198.5654\n",
      "Epoch 18/20\n",
      "173565/173565 [==============================] - 17s 96us/step - loss: 4.8915 - _perplexity: 224.1649 - val_loss: 5.9602 - val__perplexity: 4185.3817\n",
      "Epoch 19/20\n",
      "173565/173565 [==============================] - 17s 96us/step - loss: 4.8851 - _perplexity: 225.7865 - val_loss: 5.9620 - val__perplexity: 4206.4702\n",
      "Epoch 20/20\n",
      "173565/173565 [==============================] - 16s 95us/step - loss: 4.8796 - _perplexity: 227.3815 - val_loss: 5.9716 - val__perplexity: 4202.9622\n"
     ]
    }
   ],
   "source": [
    "model2.train(X,y, epochs=20, batch_size=64, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"deep tale ugly right . she 's at the moment they lady did n't n't gained a leads to keep on her down lands noel boy is afraid rush doin the women know all is blue . cigarette . i quite the try again . you are my smart . gitchi\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(first_word='deep', n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello how you were my italian bar . i ever do n't take his beat to me what it wants to the baby . they loved . bop tonight were poor and try . you have fuel i ca n't believe in an makes you . show me again . stopping\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(first_word='hello', n_words=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlinto] *",
   "language": "python",
   "name": "conda-env-dlinto-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
