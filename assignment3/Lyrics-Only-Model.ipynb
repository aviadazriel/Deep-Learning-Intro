{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from src.dataset import load_tokenized_data\n",
    "from src.model import LyricsOnlyModel\n",
    "from src.embeddings import extract_embedding_weights\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:01<00:00, 369.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:01<00:00, 356.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:02<00:00, 293.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:02<00:00, 294.06it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y, tokenizer = load_tokenized_data()\n",
    "embedding_matrix = extract_embedding_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1, 300)            2247300   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 300)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000)              3208000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7491)              7498491   \n",
      "=================================================================\n",
      "Total params: 12,953,791\n",
      "Trainable params: 10,706,491\n",
      "Non-trainable params: 2,247,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LyricsOnlyModel(tokenizer, embedding_matrix, \n",
    "                        rnn_type='LSTM', \n",
    "                        rnn_units=500, \n",
    "                        bidirectional=True,\n",
    "                        dropout=0,\n",
    "                        train_embedding=False, \n",
    "                        is_layer_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 173565 samples, validate on 19286 samples\n",
      "Epoch 1/50\n",
      "173565/173565 [==============================] - 66s 378us/step - loss: 6.9195 - _perplexity: 243.3252 - val_loss: 6.7429 - val__perplexity: 401.2054\n",
      "Epoch 2/50\n",
      "173565/173565 [==============================] - 59s 341us/step - loss: 6.2365 - _perplexity: 194.3340 - val_loss: 6.6711 - val__perplexity: 1179.7596\n",
      "Epoch 3/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 6.0632 - _perplexity: 195.0963 - val_loss: 6.6678 - val__perplexity: 3690.1047\n",
      "Epoch 4/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.9618 - _perplexity: 207.5432 - val_loss: 6.6275 - val__perplexity: 4107.2394\n",
      "Epoch 5/50\n",
      "173565/173565 [==============================] - 59s 337us/step - loss: 5.9011 - _perplexity: 223.9446 - val_loss: 6.5953 - val__perplexity: 4138.9274\n",
      "Epoch 6/50\n",
      "173565/173565 [==============================] - 58s 335us/step - loss: 5.8678 - _perplexity: 240.8439 - val_loss: 6.5425 - val__perplexity: 4143.6440\n",
      "Epoch 7/50\n",
      "173565/173565 [==============================] - 58s 334us/step - loss: 5.8466 - _perplexity: 256.1233 - val_loss: 6.5582 - val__perplexity: 4161.9637\n",
      "Epoch 8/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8353 - _perplexity: 269.2304 - val_loss: 6.5617 - val__perplexity: 4171.3057\n",
      "Epoch 9/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8306 - _perplexity: 281.5578 - val_loss: 6.6385 - val__perplexity: 4178.5697\n",
      "Epoch 10/50\n",
      "173565/173565 [==============================] - 58s 334us/step - loss: 5.8319 - _perplexity: 291.4429 - val_loss: 6.5576 - val__perplexity: 4190.8990\n",
      "Epoch 11/50\n",
      "173565/173565 [==============================] - 57s 331us/step - loss: 5.8301 - _perplexity: 299.9698 - val_loss: 6.5759 - val__perplexity: 4204.5128\n",
      "Epoch 12/50\n",
      "173565/173565 [==============================] - 57s 331us/step - loss: 5.8329 - _perplexity: 307.0789 - val_loss: 6.5680 - val__perplexity: 4210.2928\n",
      "Epoch 13/50\n",
      "173565/173565 [==============================] - 58s 334us/step - loss: 5.8342 - _perplexity: 313.5864 - val_loss: 6.5712 - val__perplexity: 4214.4369\n",
      "Epoch 14/50\n",
      "173565/173565 [==============================] - 59s 340us/step - loss: 5.8352 - _perplexity: 318.0168 - val_loss: 6.5520 - val__perplexity: 4221.1578\n",
      "Epoch 15/50\n",
      "173565/173565 [==============================] - 58s 335us/step - loss: 5.8371 - _perplexity: 322.4875 - val_loss: 6.5661 - val__perplexity: 4239.4830\n",
      "Epoch 16/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.8387 - _perplexity: 327.3259 - val_loss: 6.5809 - val__perplexity: 4233.7542\n",
      "Epoch 17/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8395 - _perplexity: 330.1129 - val_loss: 6.6052 - val__perplexity: 4229.9061\n",
      "Epoch 18/50\n",
      "173565/173565 [==============================] - 58s 334us/step - loss: 5.8413 - _perplexity: 333.2227 - val_loss: 6.6087 - val__perplexity: 4237.6914\n",
      "Epoch 19/50\n",
      "173565/173565 [==============================] - 59s 339us/step - loss: 5.8423 - _perplexity: 336.3481 - val_loss: 6.6001 - val__perplexity: 4241.7378\n",
      "Epoch 20/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.8419 - _perplexity: 338.8967 - val_loss: 6.6227 - val__perplexity: 4254.2385\n",
      "Epoch 21/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8425 - _perplexity: 340.2706 - val_loss: 6.6405 - val__perplexity: 4244.3702\n",
      "Epoch 22/50\n",
      "173565/173565 [==============================] - 59s 341us/step - loss: 5.8443 - _perplexity: 342.1408 - val_loss: 6.5862 - val__perplexity: 4252.2051\n",
      "Epoch 23/50\n",
      "173565/173565 [==============================] - 58s 335us/step - loss: 5.8465 - _perplexity: 343.6347 - val_loss: 6.6372 - val__perplexity: 4260.4814\n",
      "Epoch 24/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.8464 - _perplexity: 344.7512 - val_loss: 6.6001 - val__perplexity: 4256.3509\n",
      "Epoch 25/50\n",
      "173565/173565 [==============================] - 59s 339us/step - loss: 5.8468 - _perplexity: 346.3043 - val_loss: 6.5772 - val__perplexity: 4252.9740\n",
      "Epoch 26/50\n",
      "173565/173565 [==============================] - 60s 343us/step - loss: 5.8467 - _perplexity: 347.6326 - val_loss: 6.6481 - val__perplexity: 4258.9683\n",
      "Epoch 27/50\n",
      "173565/173565 [==============================] - 58s 335us/step - loss: 5.8472 - _perplexity: 348.7154 - val_loss: 6.6175 - val__perplexity: 4258.2531\n",
      "Epoch 28/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8496 - _perplexity: 350.3357 - val_loss: 6.6519 - val__perplexity: 4267.6875\n",
      "Epoch 29/50\n",
      "173565/173565 [==============================] - 58s 332us/step - loss: 5.8492 - _perplexity: 350.4273 - val_loss: 6.5891 - val__perplexity: 4276.4623\n",
      "Epoch 30/50\n",
      "173565/173565 [==============================] - 58s 332us/step - loss: 5.8493 - _perplexity: 351.9473 - val_loss: 6.6644 - val__perplexity: 4274.7865\n",
      "Epoch 31/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8514 - _perplexity: 352.4846 - val_loss: 6.5740 - val__perplexity: 4268.7412\n",
      "Epoch 32/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8508 - _perplexity: 352.6905 - val_loss: 6.6200 - val__perplexity: 4270.7346\n",
      "Epoch 33/50\n",
      "173565/173565 [==============================] - 58s 333us/step - loss: 5.8495 - _perplexity: 353.7600 - val_loss: 6.6768 - val__perplexity: 4267.8535\n",
      "Epoch 34/50\n",
      "173565/173565 [==============================] - 59s 341us/step - loss: 5.8500 - _perplexity: 353.8974 - val_loss: 6.5919 - val__perplexity: 4275.9252\n",
      "Epoch 35/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.8508 - _perplexity: 354.5536 - val_loss: 6.6147 - val__perplexity: 4267.8773\n",
      "Epoch 36/50\n",
      "173565/173565 [==============================] - 59s 337us/step - loss: 5.8507 - _perplexity: 354.2694 - val_loss: 6.6287 - val__perplexity: 4266.4970\n",
      "Epoch 37/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8521 - _perplexity: 355.3041 - val_loss: 6.6594 - val__perplexity: 4263.8092\n",
      "Epoch 38/50\n",
      "173565/173565 [==============================] - 58s 337us/step - loss: 5.8516 - _perplexity: 355.1557 - val_loss: 6.6811 - val__perplexity: 4267.2644\n",
      "Epoch 39/50\n",
      "173565/173565 [==============================] - 59s 340us/step - loss: 5.8517 - _perplexity: 355.9432 - val_loss: 6.6936 - val__perplexity: 4266.6900\n",
      "Epoch 40/50\n",
      "173565/173565 [==============================] - 59s 339us/step - loss: 5.8516 - _perplexity: 356.5197 - val_loss: 6.6101 - val__perplexity: 4274.3896\n",
      "Epoch 41/50\n",
      "173565/173565 [==============================] - 59s 337us/step - loss: 5.8516 - _perplexity: 356.3977 - val_loss: 6.5619 - val__perplexity: 4271.9600\n",
      "Epoch 42/50\n",
      "173565/173565 [==============================] - 58s 337us/step - loss: 5.8523 - _perplexity: 356.3850 - val_loss: 6.6309 - val__perplexity: 4267.3017\n",
      "Epoch 43/50\n",
      "173565/173565 [==============================] - 59s 339us/step - loss: 5.8521 - _perplexity: 356.7460 - val_loss: 6.6036 - val__perplexity: 4278.4978\n",
      "Epoch 44/50\n",
      "173565/173565 [==============================] - 59s 340us/step - loss: 5.8510 - _perplexity: 356.6000 - val_loss: 6.6539 - val__perplexity: 4281.8427\n",
      "Epoch 45/50\n",
      "173565/173565 [==============================] - 58s 336us/step - loss: 5.8527 - _perplexity: 357.1291 - val_loss: 6.6413 - val__perplexity: 4274.1953\n",
      "Epoch 46/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8536 - _perplexity: 357.3713 - val_loss: 6.6249 - val__perplexity: 4281.3553\n",
      "Epoch 47/50\n",
      "173565/173565 [==============================] - 59s 337us/step - loss: 5.8524 - _perplexity: 357.7128 - val_loss: 6.5672 - val__perplexity: 4283.2087\n",
      "Epoch 48/50\n",
      "173565/173565 [==============================] - 58s 337us/step - loss: 5.8527 - _perplexity: 357.4908 - val_loss: 6.5562 - val__perplexity: 4269.8587\n",
      "Epoch 49/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8532 - _perplexity: 357.6694 - val_loss: 6.6626 - val__perplexity: 4277.5623\n",
      "Epoch 50/50\n",
      "173565/173565 [==============================] - 59s 338us/step - loss: 5.8539 - _perplexity: 358.0955 - val_loss: 6.6161 - val__perplexity: 4280.2779\n"
     ]
    }
   ],
   "source": [
    "model.train(X,y, epochs=50, batch_size=32, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deep wo my . maybe me . smile i up thing of they body snow please do . and i start westward fate . it known depths of skies . do . the door . . oh for riding and war sound fell . if i do to wo right .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(first_word='deep', n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello . let me . control with the some take a one where i 'd each colors . and they crowd . maybe . see i never 'll time to going on boardwalk and sound . through . do it you lovely just what on there 's discovery not will rest\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(first_word='hello', n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1, 300)            2247300   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 300)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_3 (CuDNNGRU)       (None, 20)                19320     \n",
      "_________________________________________________________________\n",
      "layer_normalization_3 (Layer (None, 20)                40        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7491)              157311    \n",
      "=================================================================\n",
      "Total params: 2,423,971\n",
      "Trainable params: 2,423,971\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = LyricsOnlyModel(tokenizer, embedding_matrix, \n",
    "                        rnn_type='GRU', \n",
    "                        rnn_units=20, \n",
    "                        bidirectional=False,\n",
    "                        dropout=0.4,\n",
    "                        train_embedding=True, \n",
    "                        is_layer_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 173565 samples, validate on 19286 samples\n",
      "Epoch 1/20\n",
      "173565/173565 [==============================] - 19s 109us/step - loss: 6.5328 - _perplexity: 209.4088 - val_loss: 6.1412 - val__perplexity: 272.8829\n",
      "Epoch 2/20\n",
      "173565/173565 [==============================] - 17s 100us/step - loss: 5.6034 - _perplexity: 173.0512 - val_loss: 5.9148 - val__perplexity: 407.9957\n",
      "Epoch 3/20\n",
      "173565/173565 [==============================] - 17s 99us/step - loss: 5.3483 - _perplexity: 172.1896 - val_loss: 5.8775 - val__perplexity: 704.4518\n",
      "Epoch 4/20\n",
      "173565/173565 [==============================] - 18s 101us/step - loss: 5.2182 - _perplexity: 175.1970 - val_loss: 5.8910 - val__perplexity: 1279.0956\n",
      "Epoch 5/20\n",
      "173565/173565 [==============================] - 18s 101us/step - loss: 5.1365 - _perplexity: 179.4518 - val_loss: 5.9103 - val__perplexity: 2406.0689\n",
      "Epoch 6/20\n",
      "173565/173565 [==============================] - 17s 100us/step - loss: 5.0800 - _perplexity: 183.8968 - val_loss: 5.9501 - val__perplexity: 3611.3050\n",
      "Epoch 7/20\n",
      "173565/173565 [==============================] - 18s 102us/step - loss: 5.0370 - _perplexity: 188.3843 - val_loss: 5.9500 - val__perplexity: 4074.4832\n",
      "Epoch 8/20\n",
      "173565/173565 [==============================] - 17s 98us/step - loss: 5.0081 - _perplexity: 193.1159 - val_loss: 5.9535 - val__perplexity: 4119.1654\n",
      "Epoch 9/20\n",
      "173565/173565 [==============================] - 17s 101us/step - loss: 4.9846 - _perplexity: 197.7704 - val_loss: 5.9602 - val__perplexity: 4129.7011\n",
      "Epoch 10/20\n",
      "173565/173565 [==============================] - 17s 100us/step - loss: 4.9672 - _perplexity: 201.5765 - val_loss: 5.9482 - val__perplexity: 4144.4038\n",
      "Epoch 11/20\n",
      "173565/173565 [==============================] - 18s 102us/step - loss: 4.9519 - _perplexity: 205.6720 - val_loss: 5.9450 - val__perplexity: 4145.5488\n",
      "Epoch 12/20\n",
      "173565/173565 [==============================] - 20s 113us/step - loss: 4.9394 - _perplexity: 209.0926 - val_loss: 5.9603 - val__perplexity: 4148.4150\n",
      "Epoch 13/20\n",
      "173565/173565 [==============================] - 20s 113us/step - loss: 4.9289 - _perplexity: 212.5110 - val_loss: 5.9581 - val__perplexity: 4149.7242\n",
      "Epoch 14/20\n",
      "173565/173565 [==============================] - 20s 117us/step - loss: 4.9181 - _perplexity: 215.1645 - val_loss: 5.9427 - val__perplexity: 4164.1757\n",
      "Epoch 15/20\n",
      "173565/173565 [==============================] - 20s 116us/step - loss: 4.9096 - _perplexity: 217.5818 - val_loss: 5.9573 - val__perplexity: 4162.5700\n",
      "Epoch 16/20\n",
      "173565/173565 [==============================] - 20s 114us/step - loss: 4.9026 - _perplexity: 218.9232 - val_loss: 5.9460 - val__perplexity: 4168.0229\n",
      "Epoch 17/20\n",
      "173565/173565 [==============================] - 20s 117us/step - loss: 4.8963 - _perplexity: 221.2789 - val_loss: 5.9685 - val__perplexity: 4182.1281\n",
      "Epoch 18/20\n",
      "173565/173565 [==============================] - 21s 118us/step - loss: 4.8910 - _perplexity: 223.2697 - val_loss: 5.9633 - val__perplexity: 4173.8085\n",
      "Epoch 19/20\n",
      "173565/173565 [==============================] - 20s 113us/step - loss: 4.8850 - _perplexity: 224.6200 - val_loss: 5.9645 - val__perplexity: 4188.2512\n",
      "Epoch 20/20\n",
      "173565/173565 [==============================] - 20s 117us/step - loss: 4.8797 - _perplexity: 226.7408 - val_loss: 5.9539 - val__perplexity: 4183.7372\n"
     ]
    }
   ],
   "source": [
    "model2.train(X,y, epochs=20, batch_size=64, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"deep tale ugly right . she 's at the moment they lady did n't n't gained a leads to keep on her down lands noel boy is afraid rush doin the women know all is blue . cigarette . i quite the try again . you are my smart . gitchi\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(first_word='deep', n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello how you were my italian bar . i ever do n't take his beat to me what it wants to the baby . they loved . bop tonight were poor and try . you have fuel i ca n't believe in an makes you . show me again . stopping\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(first_word='hello', n_words=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
