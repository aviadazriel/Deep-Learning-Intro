{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "1. use [center loss](https://medium.com/mlreview/experiments-with-a-new-loss-term-added-to-the-standard-cross-entropy-85b080c42446)\n",
    "2. split train & val\n",
    "3. add [Beam Search](https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/)\n",
    "4. maybe add [attention](https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39)\n",
    "5. add [reg](https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import src.dataset as ds\n",
    "import numpy as np\n",
    "from src.embeddings import extract_embedding_weights\n",
    "from keras.layers import Embedding, CuDNNLSTM, Bidirectional, Dense, CuDNNGRU\n",
    "from keras.initializers import Constant\n",
    "from keras import Sequential\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from src.model import Model\n",
    "\n",
    "from time import time\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 615/615 [00:01<00:00, 365.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 615/615 [00:01<00:00, 364.01it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 615/615 [00:01<00:00, 363.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 615/615 [00:01<00:00, 362.16it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y, tokenizer = ds.load_tokenized_data()\n",
    "embedding_matrix = extract_embedding_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1, 300)            2251800   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100)               140800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7506)              758106    \n",
      "=================================================================\n",
      "Total params: 3,150,706\n",
      "Trainable params: 898,906\n",
      "Non-trainable params: 2,251,800\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Eli\\Anaconda3\\envs\\dlinto\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 154596 samples, validate on 38650 samples\n",
      "Epoch 1/2\n",
      "154596/154596 [==============================] - 42s 275us/step - loss: 5.1336 - _perplexity: 769.6594 - val_loss: 5.4209 - val__perplexity: 2604.0124\n",
      "Epoch 2/2\n",
      "154596/154596 [==============================] - 38s 248us/step - loss: 4.4788 - _perplexity: 429.9777 - val_loss: 5.4116 - val__perplexity: 3885.9883\n"
     ]
    }
   ],
   "source": [
    "model = Model(tokenizer, embedding_matrix)\n",
    "model.train(X,y, epochs=2, batch_size=20, callbacks=[tensorboard])\n",
    "# model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c:\\users\\eli\\workspace\\deep-learning-intro\\assignment3\\src\\model.py(71)predict()\n",
      "     70             ipdb.set_trace()\n",
      "---> 71             out_word = ''\n",
      "     72             for word, index in tokenizer.word_index.items():\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  proba\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[2.6724436e-09, 2.8712122e-09, 1.7368726e-05, ..., 1.6459103e-06,\n",
      "        5.8268895e-04, 2.2899949e-05]], dtype=float32)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  proba.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7506)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  proba[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([2.6724436e-09, 2.8712122e-09, 1.7368726e-05, ..., 1.6459103e-06,\n",
      "       5.8268895e-04, 2.2899949e-05], dtype=float32)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  proba[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** IndexError: index 1 is out of bounds for axis 0 with size 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  proba[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([2.6724436e-09, 2.8712122e-09, 1.7368726e-05, ..., 1.6459103e-06,\n",
      "       5.8268895e-04, 2.2899949e-05], dtype=float32)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  proba[0][0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6724436e-09\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  proba[0][1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8712122e-09\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  sum(proba)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([2.6724436e-09, 2.8712122e-09, 1.7368726e-05, ..., 1.6459103e-06,\n",
      "       5.8268895e-04, 2.2899949e-05], dtype=float32)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.sum(sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in function sum>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.sum(proba)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000001\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  proba\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[2.6724436e-09, 2.8712122e-09, 1.7368726e-05, ..., 1.6459103e-06,\n",
      "        5.8268895e-04, 2.2899949e-05]], dtype=float32)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  sorted(proba)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.6724436e-09, 2.8712122e-09, 1.7368726e-05, ..., 1.6459103e-06,\n",
      "       5.8268895e-04, 2.2899949e-05], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  proba\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[2.6724436e-09, 2.8712122e-09, 1.7368726e-05, ..., 1.6459103e-06,\n",
      "        5.8268895e-04, 2.2899949e-05]], dtype=float32)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  -np.sort(-proba)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[3.9417145e-01, 5.5460762e-02, 2.6946710e-02, ..., 2.4793119e-09,\n",
      "        1.9104485e-09, 1.1865843e-09]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model.predict('Deep', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam search\n",
    "def beam_search_decoder(first_word, n_words, beam_width=3):\n",
    "    tokenizer = self.tokenizer\n",
    "    model = self.model\n",
    "    in_text, result = first_word, first_word\n",
    "    \n",
    "\tsequences = [[list(), 1.0]]\n",
    "\t# walk over each step in sequence\n",
    "\tfor row in data:\n",
    "\t\tall_candidates = list()\n",
    "\t\t# expand each current candidate\n",
    "\t\tfor i in range(len(sequences)):\n",
    "\t\t\tseq, score = sequences[i]\n",
    "\t\t\tfor j in range(len(row)):\n",
    "\t\t\t\tcandidate = [seq + [j], score * -log(row[j])]\n",
    "\t\t\t\tall_candidates.append(candidate)\n",
    "\t\t# order all candidates by score\n",
    "\t\tordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "\t\t# select k best\n",
    "\t\tsequences = ordered[:k]\n",
    "\treturn sequences\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_step(beam_sequences_scores):            \n",
    "    all_candidates = []\n",
    "    encoded = get_encoded(in_text, tokenizer)    \n",
    "    for seq, score in beam_sequences_scores: # for each sequence\n",
    "        seq.extend(encoded) # add words till now\n",
    "        # predict top B words\n",
    "        words_probs = model.predict_proba(encoded, verbose=0)\n",
    "        words_probs_sorted = -np.sort(-words_probs) # sorting in descending order\n",
    "        top_b_words_probs = words_probs_sorted[:B] # top B words with max probability\n",
    "        # for each prob in top B words, create a candidate\n",
    "        for prob in top_b_words_probs: \n",
    "            candidate = [seq + [word_token], score + np.log(prob + epsilon())] # todo: word_token \n",
    "            all_candidates.append(candidate)\n",
    "    # take candidates with max score\n",
    "    beam_sequences_scores = sorted(all_candidates, reverse=True, key=lambda seq, score: score)[:B]\n",
    "    return beam_sequences_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import epsilon\n",
    "def predict(self, first_word, n_words, B=3):\n",
    "        tokenizer = self.tokenizer\n",
    "        model = self.model\n",
    "        in_text, result = first_word, first_word\n",
    "        beam_sequences_scores = [[list(), 0]]\n",
    "        while len(result) < n_words: \n",
    "           \n",
    "            for _ in range(B): # run till beam_width\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "        \n",
    "def get_encoded(text, tokenizer):\n",
    "    encoded = tokenizer.texts_to_sequences([text])[0]\n",
    "    encoded = np.array(encoded)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        \n",
    "        # generate a fixed number of words\n",
    "        for _ in range(n_words):\n",
    "            # encode the text as integer\n",
    "            encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "            encoded = np.array(encoded)\n",
    "            # predict a word in the vocabulary\n",
    "            proba = model.predict_proba(encoded, verbose=0)\n",
    "            import ipdb\n",
    "            ipdb.set_trace()\n",
    "            out_word = ''\n",
    "            for word, index in tokenizer.word_index.items():\n",
    "                if index == yhat:\n",
    "                    out_word = word\n",
    "                    break\n",
    "            # append to input\n",
    "            in_text, result = out_word, result + ' ' + out_word\n",
    "        return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
